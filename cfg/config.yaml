defaults:
  - models: 
    - sd15
  - datasets:
    - anime
  - losses:
    - normal

seed: 42


# model
noise_offset: 0.
prediction_type:
snr_gamma:


# training
eval: True
gradient_accumulation_steps: 1
train_batch_size: 16
dataloader_num_workers: 0
max_train_steps:
num_train_epochs: 100
max_grad_norm: 1.0

mixed_precision: "bf16"
resume_from_checkpoint: # Use a path saved or "latest"
checkpointing_steps: 50
validation_epochs: 1
num_validation_images: 4
checkpoints_total_limit:

gradient_checkpointing: False


# optimizer
learning_rate: 1e-4
use_8bit_adam: False
adam_beta1: 0.9
adam_beta2: 0.99
adam_weight_decay: 1e-2
adam_epsilon: 1e-8
lr_scheduler: "constant"
lr_warmup_steps: 500


# lora
rank: 4
lora_alpha: 4
lora_dropout: 0.0
init_lora_weights: "gaussian"
unet_target_modules: ["to_k", "to_q", "to_v", "to_out.0", "add_k_proj", "add_v_proj"]

# dreambooth
# 这部分可以移到datasets下面
# instance_data_dir: "YOUR_PATH_TO_INSTANCE_DATA"
# instance_prompt: "an anime image of xxy5syt00 girl"
# class_data_dir: "YOUR_PATH_TO_CLASS_DATA"
# class_prompt: "an anime image of girl"

prior_loss_weight: 1.0
num_class_images: 128 #128
sample_batch_size: 4
with_prior_preservation: False
prior_generation_precision: bf16
pre_compute_text_embeddings: False
text_encoder_use_attention_mask: False
train_text_encoder: False
text_encoder_target_modules: ["q_proj", "k_proj", "v_proj", "out_proj"]
tokenizer_max_length: 


# io
output_dir: "YOUR_PATH_TO_OUTPUT"

## logging
logging_dir: "./logging"
report_to: "tensorboard"